{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-7.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lZLChAvSju7z"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Key words: MNIST Digit Recognition, Keras, Neural Network, Learning rate, Gaussian Noise, Regularizaton, Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLIypktRjX_P",
        "outputId": "7e8c33f8-b48f-40cd-9dd8-2388588c1b74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "## Define model ##\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(125, activation = 'relu'))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(50, activation = 'relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=keras.optimizers.SGD(lr = 0.1),\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "fit_info = model.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=0,\n",
        "           validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Test loss: 0.10167630016803741, Test accuracy 0.9686999917030334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6clC4nE0cPld",
        "outputId": "a48e308d-24fa-4d57-d676-9e13c30eba7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 125)               98125     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               12600     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 116,285\n",
            "Trainable params: 116,285\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZLChAvSju7z"
      },
      "source": [
        "## Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW3v98u9t8_Q"
      },
      "source": [
        "## 2a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJyU_ZiqjxCv",
        "outputId": "e1565d13-4c70-44e3-b1a1-5bdc6f0bb788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "## Define model ##\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=keras.optimizers.SGD(lr = 0.1),\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "fit_info = model.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=0,\n",
        "           validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.07738284766674042, Test accuracy 0.9769999980926514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt9rNxGzqzPd"
      },
      "source": [
        "##2b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlVqVQoFqya6",
        "outputId": "cc82ab8c-95d7-4977-c232-57ccbd3486c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "loss_res = 0 \n",
        "accuracy_res = 0\n",
        "\n",
        "lr = [0.001, 0.01, 0.1, 1]\n",
        "for j in lr:\n",
        "    for i in range(0,3): \n",
        "        batch_size = 128\n",
        "        num_classes = 10\n",
        "        epochs = 10\n",
        "\n",
        "        # input image dimensions\n",
        "        img_rows, img_cols = 28, 28\n",
        "\n",
        "        # the data, split between train and test sets\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "            x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "            input_shape = (1, img_rows, img_cols)\n",
        "        else:\n",
        "            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "            input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train /= 255\n",
        "        x_test /= 255\n",
        "\n",
        "        # convert class vectors to binary class matrices\n",
        "        y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "        y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "        ## Define model ##\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(100, activation = 'relu'))\n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                        optimizer=keras.optimizers.SGD(lr = j),\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "        fit_info = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=0,\n",
        "                    validation_data=(x_test, y_test))\n",
        "        score = model.evaluate(x_test, y_test, verbose=0)\n",
        "        #print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
        "\n",
        "        loss_res = loss_res + score[0]\n",
        "        accuracy_res = accuracy_res + score[1]\n",
        "        #print (\"Loss_res: \", loss_res)\n",
        "        i=i+1\n",
        "\n",
        "    average_loss = loss_res/i\n",
        "    average_accuracy = accuracy_res/i\n",
        "    #print(\"Average loss:\", average_loss)\n",
        "    print (\"Learning rate:\", j, \"Average loss:\", average_loss, \"Average accuracy:\", average_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate: 0.001 Average loss: 0.6347366372744242 Average accuracy: 0.8574999968210856\n",
            "Learning rate: 0.01 Average loss: 0.9111403524875641 Average accuracy: 1.7792999943097432\n",
            "Learning rate: 0.1 Average loss: 1.0166819815834363 Average accuracy: 2.7488333185513816\n",
            "Learning rate: 1 Average loss: 1.1434544275204341 Average accuracy: 3.7141666412353516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OQTbpwNWOY6"
      },
      "source": [
        "# 2c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K5SFCmHLT3F",
        "outputId": "610b8376-bdb4-44af-96d5-77bf1face4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "sum_loss = 0\n",
        "sum_accuracy = 0\n",
        "neurons = [1000]\n",
        "# neurons = [10, 25, 100, 500, 1000]\n",
        "lr = [0.001, 0.025, 0.01, 0.05, 0.1]\n",
        "\n",
        "# Three iterations with same LR and neurons\n",
        "\n",
        "for i in neurons:\n",
        " model = Sequential()\n",
        " model.add(Flatten())\n",
        " model.add(Dense(i, activation = 'relu'))\n",
        " model.add(Dense(num_classes, activation='softmax'))\n",
        " print('###### No of neurons {} ######'.format(i))\n",
        "\n",
        " for j in lr:\n",
        "   model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=keras.optimizers.SGD(lr = j),\n",
        "               metrics=['accuracy'])\n",
        "   print('### Learning rate {} ###'.format(j))\n",
        "   \n",
        "   for k in range (1,4):\n",
        "     fit_info_ex = model.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=0,\n",
        "           validation_data=(x_test, y_test))\n",
        "     score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    \n",
        "     sum_loss += score[0]\n",
        "     sum_accuracy += score[1]\n",
        "   print(\"Loss\", sum_loss/3)\n",
        "   print(\"Accuracy\", sum_accuracy/3)\n",
        "   sum_loss = 0\n",
        "   sum_accuracy = 0\n",
        "   print(\"\")\n",
        " print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###### No of neurons 1000 ######\n",
            "### Learning rate 0.001 ###\n",
            "Loss 0.4538740813732147\n",
            "Accuracy 0.890333334604899\n",
            "\n",
            "### Learning rate 0.025 ###\n",
            "Loss 0.1329422319928805\n",
            "Accuracy 0.9617666602134705\n",
            "\n",
            "### Learning rate 0.01 ###\n",
            "Loss 0.08989750097195308\n",
            "Accuracy 0.9740666747093201\n",
            "\n",
            "### Learning rate 0.05 ###\n",
            "Loss 0.06748470415671666\n",
            "Accuracy 0.9796333312988281\n",
            "\n",
            "### Learning rate 0.1 ###\n",
            "Loss 0.058688404659430184\n",
            "Accuracy 0.9816333452860514\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVY-KLl-ilgo"
      },
      "source": [
        "# Task 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw-FlO5Ltj_9"
      },
      "source": [
        "3a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqJ1i2O8inTA",
        "outputId": "5742bb59-1ac4-46c0-b25e-4377e6ebdca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from keras.layers import GaussianNoise\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "seq = [0.1, 1, 10]\n",
        "\n",
        "for i in seq:\n",
        "  ## Define model ##\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(GaussianNoise(i))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(100, activation = 'relu'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=keras.optimizers.SGD(lr = 0.1),\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "  fit_info_ex = model.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=0,\n",
        "           validation_data=(x_test, y_test))\n",
        "\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Std for noise: {}'.format(i))\n",
        "  print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Std for noise: 0.1\n",
            "Test loss: 0.07007749378681183, Test accuracy 0.9793000221252441\n",
            "Std for noise: 1\n",
            "Test loss: 0.16438861191272736, Test accuracy 0.9603999853134155\n",
            "Std for noise: 10\n",
            "Test loss: 2.311164379119873, Test accuracy 0.09799999743700027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ56jl7wtmJS"
      },
      "source": [
        "3b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga-jV-GztoHO",
        "outputId": "d4e375d4-1521-4040-d4f3-a741a98875dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from keras.layers import GaussianNoise\n",
        "from keras import regularizers\n",
        "\n",
        "l2 = [0.001, 0.01, 0.1]\n",
        "for i in l2: \n",
        "    batch_size = 128\n",
        "    num_classes = 10\n",
        "    epochs = 10\n",
        "\n",
        "    # input image dimensions\n",
        "    img_rows, img_cols = 28, 28\n",
        "\n",
        "    # the data, split between train and test sets\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "        input_shape = (1, img_rows, img_cols)\n",
        "    else:\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    ## Define model ##\n",
        "    model = Sequential()\n",
        "    model.add(GaussianNoise(0.1))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation = 'relu',  kernel_regularizer=regularizers.l2(i)))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                optimizer=keras.optimizers.SGD(lr = 0.1),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    fit_info_ex = model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=0,\n",
        "            validation_data=(x_test, y_test))\n",
        "\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print (\"Regularization\", i)\n",
        "    print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regularization 0.001\n",
            "Test loss: 0.18607357144355774, Test accuracy 0.9684000015258789\n",
            "Regularization 0.01\n",
            "Test loss: 0.27307581901550293, Test accuracy 0.9498000144958496\n",
            "Regularization 0.1\n",
            "Test loss: 1.1137629747390747, Test accuracy 0.708899974822998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAvJF20FruCt"
      },
      "source": [
        "# Task 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9e4YJ4wkbnj",
        "outputId": "1d6bdb4d-a344-4877-e1be-cc145c0a59d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.layers import GaussianNoise\n",
        "from keras.layers.pooling import *\n",
        "from keras import regularizers\n",
        "\n",
        "batch_size = 28\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "## Define model ##\n",
        "model = Sequential()\n",
        "\n",
        "model.add(GaussianNoise(0.1))\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation = 'relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model.add(Dense(50, activation = 'relu', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=keras.optimizers.SGD(lr = 0.2),\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "fit_info_ex = model.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=0,\n",
        "           validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.045801907777786255, Test accuracy 0.9927999973297119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjOloJq4V8oo",
        "outputId": "061bf809-c3ae-4696-f0da-a68ba0a6f0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gaussian_noise_6 (GaussianNo (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_21 (Flatten)         (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 100)               160100    \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 203,228\n",
            "Trainable params: 203,228\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}